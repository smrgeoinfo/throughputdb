---
title: "Throughput Database Case Studies"
author: "Simon Goring"
date: "October 13, 2017"
output: 
  html_document:
    self_contained: false
    css: ../css/sjg_markdown.css
    code_folding: hide
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

Throughput is designed to facilitate the transmission of schientific cultural knowledge around data resources to assist interdisciplinary research.  We want to move anecdotal information about records from the lab to the cloud.  The goal of this document is to highlight several key case studies that inform the development of the data resource, by caturing key use patterns.

## Technology Background

At present the Throughput DB stack is at the proof of concept stage, but much of the technological infrastructure has been chosen with the data model and architecture at the forefront of the design decisions.

### API First Development

The Throughoput Database is intended as a back-end service to link data resources.  As such investment in UI/UX design is less important at this stage than investment in a well developed API.  The API will have `POST` and `GET` methods, roughly mapping to:

```
GET  resource
     body
     target
POST annotation
```

The `GET` methods will return data objects representing the resources associated with the annotation engine (the data repositories), the annotation bodies, supporting, for example, keyword searches *&cetera*, and target related searches, generally querying DOIs or other UIDs.

### neo4j

The linked nature of the data suggests that a graph database would provide the greatest support for the data model.  Here we envision several node and link types, including `person`, `resource`, `thing` data types (using the W3C Annotation and [schema.org]() data models).  Targets and Bodies would be identified through graph relationships, for example:

<div class='box curveshdw'>
<img src=images/simplest_annotation.svg align='center'>
</div>

By ensuring that bodies and targets have a common node type we can then ensure that annotation bodies themselves can be annotated.  `neo4j` has a number of packages to support Java, JavaScript, R and other programming languages.  This means that development of the API itself can be platform agnostic, thus, replication of the database and development of a new interface should provide the ability to fork the project easily.

### Docker

Docker containers act to isolate a set of system components from the underlying architecture.  Given this setup it is possible to run a system with the same custom components on a local system, a remote server, or on a collaborators system.  We use a container configured for `neo4j` using the `neo4j:3.0` container, and run using a `yaml` configuration file that points the neo4j browser to port 17474.  This way it doesn't interfere with any local instances of neo4j.

### W3C Standards

In general this model contains only four key elements.  An annotation, which is effectively an empty node used to link elements, a body and target are both the same node type, this allows an annotation body to be a target in and of itself.

### Understanding the Core Classes

<blockquote>An annotation	is considered	to be	a	set	of connected resources,	typically	including	a	body	and	target,	and	conveys that the body	is related to the	target.	The	exact	nature of	this relationship	changes	according	to the intention of the annotation,	but	the	body is	most frequently	somehow	"about" the	target.</blockquote>

<div align='right'>[W3C Annotation Standards](https://www.w3.org/annotation/)</div>
<p>

In general, this model works for the kind of annotations we want to discuss.  For example:

  * An individual makes a note about a data record  [note - annotates - record]
  * An individual tags a data record with some keywords [keywords - annotate - record]
  * A dataset is related to an existing grant [grant # - annotates - record]
  
In each of these cases, the annotation (the note, the keywords or the grant) are used to supplement the information of the underlying dataset.  We consider this a "data-focused" annotation system, so the data record is most commonly the object being annotated.  It is possible that an annotation can itself be annotated, or the body of an annotation.

An annotation assumes that each body applies to each target equally.  This may not be the case, for example, we may want to generate an annotation for a dataset that both links it to a record from another database, and explains why the records are being linked.  In this case, neither of the body elements can be considered independent of one another with respect to the target since the text must reference the URI and the URI relationship is not clear until addressed by the text annotation.

The OpenAnnotation standards provide the concept of a [Composite](http://www.openannotation.org/spec/core/multiplicity.html#Composite).  In this case, the two body elements can be bound together, indicating that they must be considered in connection to one another, and then linked to the annotation.

```cypher
[body:(composite:((body1)(body2)))]-->[annotation]-->[target:()]
```


The annotation requires some secondary information if we are going to manage annotations across the data lifecycle.  These include the `creator`, the `created` date/time stamp, the `generator`, the agent responsible for generating the reference, the date in which the serialization was `generated`, and then, potentially, `modified`.

#### Objects: Body and Target Properties

Both the body and target are of a class called `object` in the throughput R package.  An object contains the information relavent to the annotation.  It may link to a target singly, or as part of a composite (see above).  Similarly, the target is the annotation, but may be both an annotation or body (see below, add link).  For example, a user may annotate a previous annotation.

At present there is a `'misc'` element in the JSON representation.  This element is intended to contain extra information as we modify the data model, trying to determine which elements are critical for understanding, searching and retrieving data from the annotation graph.

The current implementation is a class with character elements:

```json
{'object': {'uid': 'character',
          'type': 'character',
          'value': 'character',
          'createTime':'character',
          'misc':'character'}}
```

The [`throughputdbr` package](http://github.com/throughput-ec/throughputdbr) implements only three classes of `type`: `DOI`, `URL` and `annotationText`.  This will expand as we move implementation to a Java based system.

The values for `uid` and `createTime` are generated by the server as the annotation is processed.  The user will not generate these.

#### Annotations: Empty Objects

The `annotation` object in this data model is a node with minimal information that serves to link annotation elements to a central node with a unique identifier and creation date.  As such it is a relatively lighweight element that is primarily used as a target (or source) for relationships within the graph.

```json
{'annotation':{'created':'character',
                   'uid':'character'}}
```

The user does not create or modify properties for the annotation.  These are generated automatically within the system.

#### Creator: Who makes the annotation?

The `creator` is intended to be a lightweight container to link to external data resources that manage personal information for researchers.  Our current implementation assumes the use of `ORCiD` identifiers, but is flexible enough to manage data from other services provided similar data structures.

```json
{'creator':{'identifier': 'character',
            'PropertyID': 'character',
             'firstName': 'character',
              'lastName': 'character',
                  'name': 'character',
            'createTime': 'character',
                   'uid': 'character'}}
```

We expect the `identifier` (*e.g.* `'0000-0002-2700-4605'`) to be associated with a `PropertyID` (a term borrowed from [schema.org]()) that identifies the source of the identifier (making this system flexible enough to accept outher unique identifiers, such as OpenIDs).

We borrow the terms `firstName` and `lastName` from [schema.org]()'s [`person` schema](http://schema.org/Person), allowing us to implement `JSON-LD` solutions more easily in the future, without having to cross-walk our internal vocabulary.

### Class Summary

With these three fundamental classes `object`, `creator` and `annotation` we can link all elements of the annotation database.  The capacity of `neo4j` to manage flexible data models and relationships provides us with an opportunity to begin development based on a core competency for linking datasets conceptually, through publication or annotating them individually for clarification.

Given these classes, we might expect a response to look something like this:

## Case Studies

```{r loaddb, echo=FALSE, warning=FALSE}

library(RNeo4j)
library(networkD3)
library(throughputdbr)

pass <- readr::read_lines('../auth.log')

con <- RNeo4j::startGraph("http://localhost:17474/db/data/", username = pass[1], pass[2])

```

### Cross-Database Annotation

### Linking Projects to Presentations - AGU 2017

This is empty right now. ToDo

### Individual Focused Annotation

#### An Individual Annotates One or Several Records.

In this instance, a researcher working on a project has discovered an issue with a single, or several datasets within a resource.  This issue may not be an error *per se* or a deficiency with the dataset, but may simply be an artifact of methodological or disciplinary-related procedures.  Thus, the annotation helps indicate that special steps may be required to process the data, or may indicate reasons why the data may be an outlier in analysis.

##### Duplicate analytic layers in Neotoma

In sedimentary pollen analysis it may be the case that a researcher counts multiple slides at a single depth.  In many cases these counts are summed and reported as a single value, but it may be the case that they are reported independently.  For a researcher unfamiliar with pollen analysis this may result in confusion, particularly when counts differ.  Thus, an individual encountering this issue for the first time may wish to annotate a single record.

In this case, the annotator, Simon Goring (orcid: [0000-0002-2700-4605](http://orcid.org/0000-0002-2700-4605)) creates a text annotation that targets the dataset object from Neotoma.  Given this structure we generate a graph to indicate this relationship.  Once generated as part of the larger graph and API system, the annotation can be served as part of a query relating to a number of factors.

```{r dupLayers, echo=TRUE, warning=FALSE, results='hide'}

clear_gph <- function(x) {
  cypher(x, 'MATCH (n) OPTIONAL MATCH (n)-[r]-() DELETE n,r;')
}

clear_gph(con)

user <- creator(identifier = '0000-0002-2700-4605',
                PropertyID = 'orcid',
                 firstName = 'Simon',
                  lastName = 'Goring')

body <- object(type = "TextualBody",
               value = paste0("Two samples counted at the same depth (x=94cm) with the same ages. ",
                              "It seems like these samples are two separate counts at the same depth ",
                              "and may be summed during analysis."))

target <- object(type = "URL",
                 value = "http://api.neotomadb.org/v1/data/datasets/13047")

source <- object(type = "DOI",
                 value = "10.17616/R3PD38")

link_record(      con = con, 
            generator = user, 
                 body = body, 
               target = target,
               source = source)

```

<div class='box curveshdw' align='center'>
```{r echo=FALSE, fig.align = 'center', fig.width = 4, fig.caption = 'Simple graph network for a single creator generating a single annotation, related to the Neotoma Database.', warning=FALSE}
nodes <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN DISTINCT ID(n1) AS id, LABELS(n1) AS type, '24' AS size")

edges <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN ID(n1) AS source, ID(n2) AS target, type(r1) AS type")

fd_data <- data.frame(source = (0:(nrow(nodes)-1))[match(edges$source, nodes$id)],
                      target = (0:(nrow(nodes)-1))[match(edges$target, nodes$id)],
                      rel    = edges$type)

forceNetwork(Links = fd_data, 
             Nodes = nodes, 
             Source = 'source', 
             Target = 'target', 
             Value = 'rel',
             NodeID = 'type',
             Group = 'type',
             Nodesize = 'size',
             fontSize = 14,
             height = 600,
             width = 600,
             opacity = 1,
             colourScale = JS("d3.scaleOrdinal(d3.schemeCategory10);"),
             legend = TRUE)

```

</div>

We might expect a response object in JSON to look something like this:

```json

{"data": 
  {
    "nodes": 
      [
        {
        "id":24629,
        "labels":["annotation"],
        "properties":
          {
            "uid":"9052324",
            "created":"2017-11-24 09:45:18-0800"}
          },
        {
          "id":24630,
          "labels":["creator"],
          "properties":{"lastName":"Goring",
                        "firstName":"Simon",
                        "id":"0000-0002-2700-4605",
                        "PropertyID":"orcid"}
        },
        {
          "id":24631,
          "labels":["object"],
          "properties":
            {
              "type":"TextualBody",
              "value":"Two samples counted at the same depth (x=94cm) with the same ages. \
                       It seems like these samples are two separate counts at the same depth \
                       and may be summed during analysis."
            }
        },
        {
          "id":24632,
          "labels":["object"],
          "properties":
            {
              "type":"URL",
              "value":"http://api.neotomadb.org/v1/data/datasets/13047"
            }
        },
        {
          "id":24633,
          "labels":["object", "resource"]
          "properties":
            {
              "type":"DOI",
              "value":"10.17616/R3PD38"
            }
        }
      ]
    },
  { "relationships":
    [
      {
        "id":12324,
        "labels":["created"],
        "relates":[24630,24629],
        "origin":24630
      },
      {
        "id":12324,
        "labels":["hasBody"],
        "relates":[24629,24631],
        "origin":24629
      },
      {
        "id":12324,
        "labels":["hasTarget"],
        "relates":[24629,24632],
        "origin":24629
      },
      {
        "id":12324,
        "labels":["hasResource"],
        "relates":[24632,24633],
        "origin":24632
      }
    ]
  }
}

```

##### An individual links datasets to a publication

In many cases, datasets may be used in multiple publications.  Some data resources can track this resuse, but many rely on self-reporting, and this oftenresults in incomplete data.  It may also be the case that tracking data reuse is beyond the scope of the data resource.  Thus, linking resources to publications through anotation provides a service for the data resources, but also for subsequent researchers.  Here a data user annotates datasets used in one of their publications:

```{r add_blois, echo=TRUE, warning=FALSE, message=FALSE, results='hide'}

clear_gph(con)

if('all_ds.rds' %in% list.files('data')) {
  all_neot <- readRDS('data/all_ds.rds')
} else {
  all_neot <- neotoma::get_dataset()
  saveRDS(all_neot, 'data/all_ds.rds')
}

all_matched <- readr::read_csv('../../stepps-baconizing/data/input/blois_files/2011-01-06-all.matched.lp.sites.csv')

ds_names <- sapply(all_neot, function(x) x$dataset.meta$collection.handle)

blois_sets <- sapply(match(all_matched$Handle, ds_names),
                     function(x) {
                       if (!is.na(x)) {
                         return(object(type = 'URL',
                                       value = paste0('http://api.neotomadb.org/v1/data/datasets/', 
                                                     all_neot[[x]]$dataset.meta$dataset.id)))
                       } else {
                         return(NA)
                       }
                     })

creator <- creator(identifier = '0000-0003-4048-177X',
                   PropertyID = 'orcid',
                   lastName = 'Blois',
                   firstName = 'Jessica')

target <- blois_sets

for (i in length(target):1) {
  if (!class(target[[i]]) == 'object') {
    target[[i]] <- NULL
  }
}

# Multiple body elements:
body <- list(object( type = 'TextualBody',
                    value = 'Age models rebuilt with new biostratigraphic markers.'),
             object( type = 'DOI',
                    value = '10.1016/j.quascirev.2011.04.017'))

source <- object(type = "DOI",
                value = "10.17616/R3PD38")

link_record(con = con, 
            generator = creator, 
            body = body, 
            target = target,
            source = source)

```

<div class='box curveshdw' align='center'>
```{r blois_graph, echo=FALSE, fig.width = 4, fig.caption = 'Simple graph network for a single creator generating a single annotation, related to the Neotoma Database.'}

nodes <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN DISTINCT ID(n1) AS id, LABELS(n1) AS type, '12' AS size")

edges <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN ID(n1) AS source, ID(n2) AS target, type(r1) AS type")

fd_data <- data.frame(source = (0:(nrow(nodes)-1))[match(edges$source, nodes$id)],
                      target = (0:(nrow(nodes)-1))[match(edges$target, nodes$id)],
                      rel    = edges$type)

forceNetwork(Links = fd_data,
             Nodes = nodes,
             Source = 'source',
             Target = 'target',
             Value = 'rel',
             NodeID = 'type',
             Group = 'type',
             Nodesize = 'size',
             height = 600,
             width = 600,
             opacity = 1,
             colourScale = JS("d3.scaleOrdinal(d3.schemeCategory10);"))

```

</div>

### Data resource linking

Here we have two records, one, a set of pollen records from Neotoma, the other a set of records within the Arctic Data Center.  In this first code block, a researcher (Jack Williams, University of Wisconsin) notes that a set of records added to the Arctic Data Center are linked to a publication in PNAS:

```{r add_ads, echo=TRUE, warning=FALSE, message=FALSE, results='hide'}

clear_gph(con)

creator <- creator(identifier = '0000-0001-6046-9634',
                   PropertyID = 'orcid',
                    firstName = 'John',
                     lastName = 'Williams')

body <- list(object(type = 'annotationText',
                   value = 'All resources linked by publication and project as part of the St Paul\'s project.'),
             object(type = 'DOI',
                   value = '10.1073/pnas.1604903113'))

target <- list(object(type = 'DOI',
                     value = '10.18739/A27N5S'),
               object(type = 'DOI',
                     value = '10.18739/A2X68N'),
               object(type = 'DOI',
                     value = '10.18739/A2MH0X'))

source <- object(type = 'DOI',
                value = '10.17616/R37P98')

link_record(con = con, 
            generator = creator, 
            body = body, 
            target = target,
            source = source)

```

Some of the records linked by Dr. Williams are also in Neotoma, and, as such, these records can be linked in any number of ways. In this case, Simon Goring links the resources by noting that one of the Arctic Data Center records represents the same physical object (it's the same core) as the pollen object within Neotoma:

```{r neotoma_to_ads, echo=TRUE, warning=FALSE, message=FALSE, results='hide'}

creator <- creator(identifier = '0000-0002-2700-4605',
                   PropertyID = 'orcid',
                    firstName = 'Simon',
                     lastName = 'Goring')

body <- list(object(type = 'annotationText',
                   value = 'The Neotoma record has a set of geophysical data recorded in the Arctic Data Center.  It\'s all part of the same analysis.'),
             object(type = 'DOI',
                   value = '10.18739/A27N5S'))

target <- object(type = 'URL',
                value = 'http://apps.neotomadb.org/explorer/?datasetid=20188')

source <- object(type = "DOI",
                value = "10.17616/R3PD38")

link_record(con = con, 
            generator = creator, 
            body = body, 
            target = target,
            source = source)

```

This then produces the following graph:

<div class='box curveshdw' align='center'>
```{r ads_neotoma_graph, echo=FALSE, fig.align = 'center', fig.width = 4, fig.caption = 'Two annotations linked through the database model, providing greater insight into the records.'}

nodes <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN DISTINCT ID(n1) AS id, LABELS(n1) AS type, '12' AS size")

edges <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN ID(n1) AS source, ID(n2) AS target, type(r1) AS type")

fd_data <- data.frame(source = (0:(nrow(nodes)-1))[match(edges$source, nodes$id)],
                      target = (0:(nrow(nodes)-1))[match(edges$target, nodes$id)],
                      rel    = edges$type)

forceNetwork(Links = fd_data, 
             Nodes = nodes, 
             Source = 'source', 
             Target = 'target', 
             Value = 'rel',
             NodeID = 'type',
             Group = 'type',
             Nodesize = 'size',
             height = 600,
             width = 600,
             opacity = 1,
             colourScale = JS("d3.scaleOrdinal(d3.schemeCategory10);"))

```

</div>

In this way, the dataset, through this graph, is now connected to the publication indirectly.  There is no requirement that the database add this information, it can be discovered through the annotation engine API.  

#### Data resource modification

Neotoma contains a large number of paleoecological records obtained from lake sediment.  The lakes are identified by name and location is reported using latitude and longitude coordinates.  Data publication for records in Neotoma spans nearly 60 years (**check**), and, as such, the earliest reported locations often had low precision, either rounding when locations were reported as DMS, or as a result of uncertainty when reporting location based on the use of topographic maps.

A recent project by Neotoma resulted in the conversion of locations within the database.  Some lake sites had coordinates changed, some sites were unchanged, but additional informaton was added to the resources (for example, original publications were checked and it was not possible to correct the location).

For this exercise we rely on a single annotation that can connect the neotoma data objects resources to a script, a csv table and a text annotation.

### A resource annotates records

There may be occasions where a script, written by an individual, but associated with a resource, may annotate records.  For example, Neotoma and the Paleobiology Database share certain records, but this may not be entirely apparent, or one database may use a script or workflow to improve geolocation of data resources from historical papers.  In this case it may be useful to annotate records to either identify links across resources, or to identify any post-processing that has occurred within the resource.

### An individual scripts a tool to link resources

In this case a user has written a script to link a data resource, and the R package written for that resource, to resources in GitHub.  The intention here is to survey ways in which the data resource is being used in analytic workflows.

```{r ropensci_links, echo=TRUE, warning=FALSE, message=FALSE, results='hide'}

clear_gph(con)

ropensci_registry <- jsonlite::fromJSON("https://raw.githubusercontent.com/ropensci/roregistry/master/registry.json")

packages <- ropensci_registry$packages$name

gh_token <- scan('gh.token', what = 'character')

if('all_github.rds' %in% list.files('data')) {
  test_pks <- readRDS('data/all_github.rds')
} else {
  test_pks <- list()  
}

script_home <- 'https://github.com/throughput-ec/throughputdb/blob/master/populate/case_study.Rmd'

for (i in 1:length(packages)) { 
  
  # I had to serialize this to avoid getting caught by GitHub's abuse detection.
  
  x <- packages[i]
  
  
  if (!length(test_pks) >= i) {
    Sys.sleep(5) # This is probably longer than it needs to be. . . 

    repos <- gh::gh(paste0('/search/code?q=library(',x,
                           ')+in:file+language:R+extension:R+extension:Rmd'), 
                     .token = gh_token)
       
    annotation_text <- paste0("The GitHub repository uses the package ",
                              x, " in a `library()` or `require()` call.")
    
    repo_list <- unique(sapply(repos$items, function(x)x$repository$html_url))
    
    target_list <- lapply(repo_list,
                          function(y) { 
                            if(length(repo_list) > 0) {
                              return(object(value = y, type = 'URL')) 
                              } else { return(NULL) }
                            }
                          )
    
    if (length(target_list) > 0) {
    
      test_pks[[i]] <- list(
        target = target_list,
        body = list(object(value = paste0('http://github.com/ropensci/',x), 
                                     type = 'URL'),
                    object( type = "annotationText",
                           value = annotation_text),
                    object(type = 'URL',
                          value = script_home)),
        generator = creator(identifier = '0000-0002-2700-4605',
                                    PropertyID = 'orcid',
                                      lastName = 'Goring',
                                     firstName = 'Simon'),
                body_rel = object(type = 'URL',
                                 value = 'https://ropensci.org/'),
                source = object(type = 'URL',
                                value = 'http://github.com'))
    } else {
      test_pks[[i]] <- list()
    }
  }
  
  if (length(test_pks[[i]]) > 0) {
    
    link_record(con,
                target = test_pks[[i]]$target,
                  body = test_pks[[i]]$body,
             generator = test_pks[[i]]$generator,
              body_rel = test_pks[[i]]$body_rel,
                source = test_pks[[i]]$source)
  }
  
  saveRDS(object = test_pks, file = 'data/all_github.rds')
  cat(i, '\n')
  
}

```

<div class='box curveshdw' align='center'>

```{r ropensci_graph, echo=FALSE, fig.align = 'center', fig.width = 4, fig.caption = 'rOpenSci package use within the GitHub environment.'}

nodes <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN DISTINCT ID(n1) AS id, LABELS(n1) AS type, '12' AS size LIMIT 300")

edges <- cypher(con, "MATCH (n1)-[r1]-(n2)
                      RETURN ID(n1) AS source, ID(n2) AS target, type(r1) AS type LIMIT 300")

fd_data <- data.frame(source = (0:(nrow(nodes)-1))[match(edges$source, nodes$id)],
                      target = (0:(nrow(nodes)-1))[match(edges$target, nodes$id)],
                      rel    = edges$type)

forceNetwork(Links = fd_data, 
             Nodes = nodes, 
             Source = 'source', 
             Target = 'target', 
             Value = 'rel',
             NodeID = 'type',
             Group = 'type',
             Nodesize = 'size',
             height = 600,
             width = 600,
             opacity = 1,
             colourScale = JS("d3.scaleOrdinal(d3.schemeCategory10);"))

```

</div>

